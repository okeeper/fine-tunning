{
    "model_args": {
        "model_name_or_path": "/opt/llama/Llama-2-7b-chat-hf",
        "use_auth_token": true,
        "token": "",
        "trust_remote_code": false,
        "torch_dtype": "float16"
    },
    "data_args": {
        "dataset_name": "thu-coai/lccc",
        "dataset_config_name": null,
        "train_file": null,
        "validation_file": null,
        "test_file": null,
        "max_train_samples": 10000,
        "max_eval_samples": 1000,
        "streaming": false,
        "block_size": 512,
        "overwrite_cache": false,
        "preprocessing_num_workers": 4,
        "max_turns": 3,
        "output_dir": "./data/processed",
        "val_size": 0.1,
        "seed": 42
    },
    "training_args": {
        "output_dir": "./output/llama2-7b-chat-lccc",
        "num_train_epochs": 2.0,
        "per_device_train_batch_size": 2,
        "per_device_eval_batch_size": 4,
        "gradient_accumulation_steps": 16,
        "learning_rate": 2e-5,
        "weight_decay": 0.01,
        "max_grad_norm": 1.0,
        "warmup_ratio": 0.03,
        "logging_steps": 10,
        "eval_steps": 100,
        "save_steps": 500,
        "save_total_limit": 3,
        "report_to": "wandb",
        "run_name": "llama2-7b-chat-lccc"
    },
    "lora_args": {
        "lora_r": 4,
        "lora_alpha": 16,
        "lora_dropout": 0.05,
        "target_modules": ["q_proj", "v_proj", "k_proj", "o_proj", "gate_proj", "up_proj", "down_proj"],
        "bias": "none"
    },
    "eval_args": {
        "eval_original_tasks": true,
        "original_task_datasets": ["squad", "glue/sst2"],
        "perplexity_eval": true,
        "knowledge_eval": true,
        "knowledge_dataset": "truthful_qa",
        "overfitting_analysis": true
    }
} 